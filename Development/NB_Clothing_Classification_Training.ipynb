{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Garments Classification Model"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Import Requirements"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "from fastai.vision.data import ImageDataLoaders\n",
       "from fastai.vision.all import *\n",
       "from fastai.imports import *\n",
       "import fastbook as fb\n",
       "import gc\n",
       "import pandas as pd\n",
       "import pickle\n",
       "import numpy as np\n",
       "from pathlib import Path\n",
       "\n",
       "%matplotlib inline"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Import dataset"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "list_cloth_path = \"../Dataset/DeepFashion_DS/DeepFashion_DS_TextFiles/list_category_cloth.txt\"\n",
       "list_img_path = \"../Dataset/DeepFashion_DS/DeepFashion_DS_TextFiles/list_category_img.txt\"\n",
       "\n",
       "df_cloth=pd.read_csv(list_cloth_path,skiprows=1,delim_whitespace=True)\n",
       "df_img=pd.read_csv(list_img_path,skiprows=1,delim_whitespace=True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "df_cloth.to_dict()\n",
       "category_map = df_cloth\n",
       "category_map[\"value\"] = category_map.index + 1"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "dict_category = category_map.set_index(\"value\").to_dict()[\"category_name\"]\n",
       "dict_cloth = category_map.set_index(\"category_name\").to_dict()[\"category_type\"]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "df = df_img\n",
       "df[\"category_label\"] = df[\"category_label\"].map(dict_category)\n",
       "df[\"garment_type\"] = df[\"category_label\"].map(dict_cloth)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "df[\"image_name\"] = df[\"image_name\"].str.replace(\"img/\",\"DeepFashion_DS/DeepFashion_DS_IMG/\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "df"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "shoe_df = pd.DataFrame(columns = ['image_name', 'category_label'])\n",
       "\n",
       "root = \"../Dataset/EdgeNet_Shoe_DS/training/\"\n",
       "dirlist = [ item for item in os.listdir(root) if os.path.isdir(os.path.join(root, item)) ]\n",
       "\n",
       "for category_name in dirlist:\n",
       "    route = root + category_name + \"/\"\n",
       "    \n",
       "    directory = os.fsencode(route)\n",
       "\n",
       "    for file in os.listdir(directory): #for cycle to iterate over folder\n",
       "        filename = os.fsdecode(file) #get file name\n",
       "        if filename.endswith(\".jpg\"): #if ends with .jpg\n",
       "            shoe_df = shoe_df.append({'image_name' : str(\"EdgeNet_Shoe_DS/training/\"+category_name+\"/\"+filename), 'category_label' : category_name},ignore_index = True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "with open('../Dataset/DeepFashion_DS/DeepFashion_DS_TextFiles/train.txt') as f:\n",
       "    train_list = f.read().splitlines()\n",
       "\n",
       "train_list = [row.replace(\"img/\",\"DeepFashion_DS/DeepFashion_DS_IMG/\") for row in train_list]\n",
       "\n",
       "cloth_df = df[df[\"image_name\"].isin(train_list)].drop(\"garment_type\",axis=1)\n",
       "\n",
       "frames = [cloth_df,shoe_df]\n",
       "\n",
       "complete_df = pd.concat(frames)\n",
       "\n",
       "complete_df.to_csv(\"../Dataset/train_list.csv\",index=False)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Image Load"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "PATH = \"../Dataset/\"\n",
       "TRAINING_PATH = \"train_list.csv\"\n",
       "\n",
       "data = ImageDataLoaders.from_csv(PATH, csv_fname=TRAINING_PATH,\n",
       "                                 item_tfms=Resize(300),\n",
       "                                 batch_tfms=aug_transforms(size=224, min_scale=0.9),\n",
       "                                 valid_pct=0.1,\n",
       "                                 splitter=RandomSplitter(seed=42), #seed=42\n",
       "                                 num_workers=0)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "gc.collect()\n",
       "torch.cuda.empty_cache()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "data.show_batch(max_n=7, nrows=1)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Model Training"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn = cnn_learner(data, resnet34, metrics=[accuracy,error_rate], pretrained=True)\n",
       "learn.fine_tune(3)\n",
       "learn.save('stage-1_resnet34')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "gc.collect()\n",
       "torch.cuda.empty_cache()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Learning rate finder"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn = cnn_learner(data, resnet34, metrics=accuracy)\n",
       "lr_steep = learn.lr_find()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "lr_steep"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "gc.collect()\n",
       "torch.cuda.empty_cache()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn.fine_tune(8, base_lr=5e-3)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Discriminative Learning Rates"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "gc.collect()\n",
       "torch.cuda.empty_cache()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn.unfreeze()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn.lr_find()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn.fit_one_cycle(6, lr_max=slice(1e-7, 1e-3))"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn.lr_find()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn.fit_one_cycle(3, lr_max=slice(1e-7, 1e-3))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Export model"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "#modelname = learn.model\n",
       "#modelname.cpu()\n",
       "#torch.save(modelname, '../Model/stage-1_resnet34.pkl')\n",
       "learn.export(\"../Model/stage-1_resnet34.pkl\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Evaluation"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Mappings"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "category_dict = {\n",
       "    \"top\":      1,\n",
       "    \"bottom\":   2, \n",
       "    \"shoes\":    3,\n",
       "    \"onepiece\": 4   # ignored in the MVP version\n",
       "}\n",
       "\n",
       "formality_dict = {\n",
       "    \"formality\":3,\n",
       "    \"casual\":2, \n",
       "    \"sport\":1\n",
       "}\n",
       "\n",
       "weather_dict = {\n",
       "    \"cold\":3,\n",
       "    \"sunny\":2, \n",
       "    \"rainny\":1\n",
       "}\n",
       "\n",
       "type_dict = {    # category, formality, weather\n",
       "\"Anorak\" :        (1, 1, 3),\n",
       "\"Blazer\":         (1, 3, 2),\n",
       "\"Blouse\":         (1, 2, 2),\n",
       "\"Bomber\" :        (1, 2, 3),\n",
       "\"Button-Down\":    (1, 2, 2 ),\n",
       "\"Cardigan\" :      (1, 2, 3),\n",
       "\"Flannel\" :       (1, 2, 3),\n",
       "\"Halter\":         (1,2,2),\n",
       "\"Henley\" :        (1, 2,3),\n",
       "\"Hoodie\" :        (1, 2, 3),\n",
       "\"Jacket\" :        (1, 2, 3),\n",
       "\"Jersey\"  :       (1, 1, 2),\n",
       "\"Parka\"   :       (1,2,3),\n",
       "\"Peacoat\" :       (1,3,3),\n",
       "\"Poncho\" :        (1,2,3),\n",
       "\"Sweater\"  :      (1,2,3),\n",
       "\"Tank\" :          (1,3,2),\n",
       "\"Tee\" :           (1,2,2),\n",
       "\"Top\"  :          (1,2,2),\n",
       "\"Turtleneck\" :    (1,3,3),\n",
       "\"Capris\" :        (2,2,2),\n",
       "\"Chinos\"  :       (2,2,2),\n",
       "\"Culottes\"  :     (2,2,2),\n",
       "\"Cutoffs\" :       (2,2,2),\n",
       "\"Gauchos\"  :      (2,2,2),\n",
       "\"Jeans\" :         (2,2,2),\n",
       "\"Jeggings\" :      (2,2,2),\n",
       "\"Jodhpurs\"  :     (2,1,2),\n",
       "\"Joggers\"  :      (2,1,3),\n",
       "\"Leggings\"  :     (2,1,2),\n",
       "\"Sarong\"  :       (2,2,2),\n",
       "\"Shorts\"  :       (2,2,2),\n",
       "\"Skirt\"   :       (2, 2,2),\n",
       "\"Sweatpants\" :    (2, 1, 3),\n",
       "\"Sweatshorts\" :   (2, 1, 2 ),\n",
       "\"Trunks\"       :  (2, 1, 2),\n",
       "\"Caftan\"       :  (4,3,2),\n",
       "\"Cape\"         :  (4,3,3),\n",
       "\"Coat\"         :  (4, 3, 3),\n",
       "\"Coverup\"      :  (4, 2, 2),\n",
       "\"Dress\"        :  (4, 2, 2),\n",
       "\"Jumpsuit\"     :  (4, 2, 2),\n",
       "\"Kaftan\"        : (4, 3, 2),\n",
       "\"Kimono\"         :(4, 3, 2),\n",
       "\"Nightdress\"     :(4, 2, 2),\n",
       "\"Onesie\"         :(4, 2, 2),\n",
       "\"Robe\"           :(4, 2, 2),\n",
       "\"Romper\"       :  (4, 2, 2),\n",
       "\"Shirtdress\"    : (4, 2, 2),\n",
       "\"Sundress\"     :  (4, 2, 2),\n",
       "\"boots\":(3, 2, 3) ,\n",
       "\"flip_flops\":(3, 2, 3),\n",
       "\"loafers\":(3, 3, 2),\n",
       "\"sandals\":(3, 2, 2),\n",
       "\"sneakers\":(3, 2, 2),\n",
       "\"soccer_shoes\":(3,1,2)}"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "inv_category_dict = dict(zip(category_dict.values(), category_dict.keys()))\n",
       "inv_formality_dict = dict(zip(formality_dict.values(), formality_dict.keys()))\n",
       "inv_weather_dict = dict(zip(weather_dict.values(), weather_dict.keys()))"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "type_df = pd.DataFrame(type_dict).T\n",
       "type_df.columns = ['Garment_type', 'Formality', 'Weather']"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "type_df[\"Garment_type\"]=type_df[\"Garment_type\"].map(inv_category_dict)\n",
       "type_df[\"Formality\"]=type_df[\"Formality\"].map(inv_formality_dict)\n",
       "type_df[\"Weather\"]=type_df[\"Weather\"].map(inv_weather_dict)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "type_df"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Predict"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "pred_df = pd.DataFrame(columns=[\"image_name\",\"category_label\",\"pred_category_label\",\"garment_type\",\"formality\",\"weather\"])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "pred_df[\"image_name\"] = complete_df[\"image_name\"]\n",
       "pred_df[\"category_label\"] = complete_df[\"category_label\"]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "pred_df = pred_df.drop(pred_df[pred_df[\"category_label\"]==\"Dress\"].index)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "pred_df.reset_index().drop([\"index\"], axis=1)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "learn = load_learner('../Model/stage-1_resnet34.pkl')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "permuted_indices = np.random.permutation(len(pred_df))\n",
       "N_PARTITIONS = 5\n",
       "dfs = []\n",
       "for i in range(N_PARTITIONS):\n",
       "    dfs.append(pred_df.iloc[permuted_indices[i::N_PARTITIONS]])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "dfs[0]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "pd.options.mode.chained_assignment = None  # default='warn'"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "cont = 1\n",
       "avance = 1\n",
       "for slice_pred_df in dfs:\n",
       "    for image in slice_pred_df[\"image_name\"]:\n",
       "        image_path = \"../Dataset/\"+image\n",
       "        slice_pred_df.loc[slice_pred_df[\"image_name\"]==image,\"pred_category_label\"]=learn.predict(image_path)[0]\n",
       "        gc.collect()\n",
       "        torch.cuda.empty_cache()\n",
       "        print(avance)\n",
       "        avance+=1\n",
       "    filepath = Path(\"Development/Predicted_DF/\"+\"pred_df\"+str(cont)+\".csv\") \n",
       "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
       "    slice_pred_df.to_csv(filepath,index=False)\n",
       "    cont+=1\n",
       "    gc.collect()\n",
       "    torch.cuda.empty_cache()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "df1 = pd.read_csv(\"../Development/Predicted_DF/pred_df1.csv\")\n",
       "df2 = pd.read_csv(\"../Development/Predicted_DF/pred_df2.csv\")\n",
       "df3 = pd.read_csv(\"../Development/Predicted_DF/pred_df3.csv\")\n",
       "df4 = pd.read_csv(\"../Development/Predicted_DF/pred_df4.csv\")\n",
       "df5 = pd.read_csv(\"../Development/Predicted_DF/pred_df5.csv\")\n",
       "\n",
       "complete_pred_df = pd.concat([df1,df2,df3,df4,df5])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "complete_pred_df[\"garment_type\"] = complete_pred_df[\"pred_category_label\"].map(type_dict)\n",
       "complete_pred_df"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def tuple_split(x, pos):\n",
       "    return x[pos]\n",
       "complete_pred_df['formality'] = complete_pred_df.apply(lambda x: tuple_split(x['garment_type'], 1),axis=1)\n",
       "complete_pred_df['weather'] = complete_pred_df.apply(lambda x: tuple_split(x['garment_type'], 2),axis=1)\n",
       "complete_pred_df['garment_type'] = complete_pred_df.apply(lambda x: tuple_split(x['garment_type'], 0),axis=1)\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
       "filepath = Path(\"Predicted_DF/complete_pred_df.csv\") \n",
       "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
       "complete_pred_df.to_csv(filepath,index=False)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3.8.10 ('FastFit_AI_env': venv)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     },
     "orig_nbformat": 4,
     "vscode": {
      "interpreter": {
       "hash": "4c2ec4f83737ed41bb948327bceb9def7a605890cff8b9e773a2698c8e88e724"
      }
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }